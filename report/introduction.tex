\section{Introduction}

Untyped lambda calculus provides and interesting target for synthesis for
  two major reasons:
  \begin{enumerate}
    \item The grammar describing the language is very small, meaning that
      small optimizations in the search process are very important to
      constrain the search space as much as possible
      %% TODO: This isn't quite the right description
    \item Untyped lambda calculus uses the exact same grammar to describe
      both terms, and functions; the meaning for a function only exists
      in the context of a specific encoding of your chosen terms.
  \end {enumerate}
The second reason in particular is interesting, because it begs the
  question of creating a specification for the behavior of functions
  independently of a given encoding.
This would allow users of the synthesizer to either pre-specify a
  particular encoding of terms they are interested in synthesizing
  functions for, or to specify the behavior of terms in the context of
  function applications, and have the synthesizer synthesize both
  an encoding for the terms, and the functions requested.
We call synthesis of terms and functions from a single unified encoding
  \emph{co-synthesis}.

\subsection{Grammar}

The grammar for untyped lambda calculus is simply defined as:
  \begin{grammar}
    <expr> ::= x
      \alt <expr> <expr>
      \alt \lambda x <expr>
  \end{grammar} \\
  where $x$ is a variable.
Note that variables need not necessarily be bound by the immediately
  preceeding lambda to be referenced.
For our purposes, variables only need be bound in the ultimate term
  that we eventually produce, as we can assume without loss of
  generality that there is no outside environment that we reference
  for synthesized terms or functions.

This grammar is very compact, which means that our search space tends to
  blow up because of the necessary depth of the search, rather than
  because the number of possible terms enumerable at a given depth
  is large.

\subsection{Evaluation Strategy}

The meaning of a term in Lambda calculus, as in other programming languages,
  depends on the evaluation strategy used to assign meaning to that term.
For our purposes, we use normal order evaluation.
Normal order evaluation evaluates the leftmost outtermost reducible
  expression first.
Although this will generate different terms than another strategy like
  applicative order, there is nothing specialized about this synthesis
  that requires normal order to be used above anything else.
We have simply chosen normal order for consistency.
